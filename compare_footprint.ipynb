{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3429710",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from os import listdir, makedirs, remove\n",
    "from os.path import isfile, join, exists\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from cartopy import crs\n",
    "from sklearn import metrics\n",
    "\n",
    "font = {'weight' : 'bold', 'size' : 14}\n",
    "matplotlib.rc('font', **font)\n",
    "# show all rows\n",
    "pd.set_option('display.max_rows', None)\n",
    "# # hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b10ba5",
   "metadata": {},
   "source": [
    "# 1. Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb49f1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_nan(s,o):\n",
    "    \"\"\"\n",
    "    this functions removed the data  from simulated and observed data\n",
    "    whereever the observed data contains nan\n",
    "    s: simulated\n",
    "    o: observed\n",
    "    \"\"\"\n",
    "    if np.sum(~np.isnan(s*o))>=1:\n",
    "#         data = np.array([s.flatten(),o.flatten()])\n",
    "        data = np.array([s,o])\n",
    "        data = np.transpose(data)\n",
    "        data = data[~np.isnan(data).any(1)]\n",
    "        s = data[:,0]\n",
    "        o = data[:,1]\n",
    "    return s, o\n",
    "\n",
    "def correlation(s,o):\n",
    "    \"\"\"\n",
    "    correlation coefficient\n",
    "        s: simulated\n",
    "        o: observed\n",
    "        correlation: correlation coefficient\n",
    "    \"\"\"\n",
    "    s,o = filter_nan(s,o)\n",
    "    if s.size == 0:\n",
    "        corr = np.NaN\n",
    "    else:\n",
    "        corr = np.corrcoef(o, s)[0,1]\n",
    "        \n",
    "    return corr\n",
    "\n",
    "def rmse(s,o):\n",
    "    \"\"\"\n",
    "    Root Mean Squared Error\n",
    "    s: simulated\n",
    "    o: observed\n",
    "    rmses: root mean squared error\n",
    "    \"\"\"\n",
    "    s,o = filter_nan(s,o)\n",
    "    return np.sqrt(np.mean((s-o)**2))\n",
    "\n",
    "def mae(s,o):\n",
    "    \"\"\"\n",
    "    Mean Absolute Error\n",
    "    s: simulated\n",
    "    o: observed\n",
    "    \"\"\"\n",
    "    s,o = filter_nan(s,o)\n",
    "    return np.mean(abs(s-o))\n",
    "\n",
    "def bias(s,o):\n",
    "    \"\"\"\n",
    "    Bias\n",
    "    s: simulated\n",
    "    o: observed\n",
    "    \"\"\"\n",
    "    s,o = filter_nan(s,o)\n",
    "    return np.mean(s-o)\n",
    "\n",
    "def index_agreement(s, o):\n",
    "    \"\"\"index of agreement Willmott (1981, 1982) \n",
    "        s: simulated\n",
    "        o: observed\n",
    "        ia: index of agreement\n",
    "    \"\"\"\n",
    "    s,o = filter_nan(s,o)\n",
    "    ia = 1 -(np.sum((o-s)**2))/(np.sum((np.abs(s-np.mean(o))+np.abs(o-np.mean(o)))**2))\n",
    "    return ia\n",
    "\n",
    "def rdmf(s, o):\n",
    "    \"\"\"Relative Difference of the mean footprint\"\"\"\n",
    "    s,o = filter_nan(s,o)\n",
    "    # zero division, e.g. both footprints are zero,set footprint 1\n",
    "    s.setflags(write=1)\n",
    "    o.setflags(write=1)\n",
    "    z = s+o\n",
    "    s[z==0]=1\n",
    "    o[z==0]=1\n",
    "#     percentage = np.mean(s - o)/np.mean((s+o)/2 )* 100\n",
    "    percentage = (s - o)/o * 100\n",
    "    \n",
    "    return np.mean(percentage),np.std(percentage)\n",
    "\n",
    "def get_darray_r(array_r,darray_temp):\n",
    "    \"\"\"convert array r to xarray dataarray\n",
    "        array_r: target array\n",
    "        darray_temp: provide darray shape, i.e. lon and lat for the array\n",
    "    \"\"\"\n",
    "    darray_r = xr.DataArray(\n",
    "        array_r,\n",
    "        dims=[\"lat\",\"lon\"],\n",
    "        coords=dict(\n",
    "            lat = np.array(darray_temp['lat']),\n",
    "            lon = np.array(darray_temp['lon'])\n",
    "        ),\n",
    "        attrs = dict(\n",
    "            description = \"Pearson correlation coefficient\"\n",
    "        )\n",
    "    )\n",
    "    darray_r.name = \"r\"\n",
    "    darray_r.attrs[\"units\"] = \"1\"\n",
    "    darray_r.attrs[\"long_name\"] = \"Pearson correlation coefficient\"\n",
    "\n",
    "    darray_r.lon.attrs['units'] = \"degrees_east\"\n",
    "    darray_r.lon.attrs['long_name'] = \"longitude in degree east\"\n",
    "    darray_r.lon.attrs['description'] = \"grid cell centers\"\n",
    "    darray_r.lon.attrs['axis'] = \"X\"\n",
    "\n",
    "    darray_r.lat.attrs['units'] = \"degrees_north\"\n",
    "    darray_r.lat.attrs['long_name'] = \"longitude in degree north\"\n",
    "    darray_r.lat.attrs['description'] = \"grid cell centers\"\n",
    "    darray_r.lat.attrs['axis'] = \"Y\"\n",
    "    return darray_r\n",
    "\n",
    "def get_darray_rmse(array_rmse,darray_temp):\n",
    "    \"\"\"convert array rmse to xarray dataarray\n",
    "        darray_rmse: target array\n",
    "        darray_temp: provide darray shape, i.e. lon and lat for the array\n",
    "    \"\"\"\n",
    "    darray_rmse = xr.DataArray(\n",
    "        array_rmse,\n",
    "        dims=[\"lat\",\"lon\"],\n",
    "        coords=dict(\n",
    "            lat = np.array(darray_temp['lat']),\n",
    "            lon = np.array(darray_temp['lon'])\n",
    "        ),\n",
    "        attrs = dict(\n",
    "            description = \"Root Mean Squared Error\"\n",
    "        )\n",
    "    )\n",
    "    darray_rmse.name = \"rmse\"\n",
    "    darray_rmse.attrs[\"units\"] = \"ppm per (micromol m-2 s-1)\"\n",
    "    darray_rmse.attrs[\"long_name\"] = \"Root Mean Squared Error\"\n",
    "\n",
    "    darray_rmse.lon.attrs['units'] = \"degrees_east\"\n",
    "    darray_rmse.lon.attrs['long_name'] = \"longitude in degree east\"\n",
    "    darray_rmse.lon.attrs['description'] = \"grid cell centers\"\n",
    "\n",
    "    darray_rmse.lat.attrs['units'] = \"degrees_north\"\n",
    "    darray_rmse.lat.attrs['long_name'] = \"longitude in degree north\"\n",
    "    darray_rmse.lat.attrs['description'] = \"grid cell centers\"\n",
    "    return darray_rmse\n",
    "\n",
    "def get_darray_mae(array_mae,darray_temp):\n",
    "    \"\"\"convert array mae to xarray dataarray\n",
    "        darray_mae: target array\n",
    "        darray_temp: provide darray shape, i.e. lon and lat for the array\n",
    "    \"\"\"\n",
    "    darray_mae = xr.DataArray(\n",
    "        array_mae,\n",
    "        dims=[\"lat\",\"lon\"],\n",
    "        coords=dict(\n",
    "            lat = np.array(darray_temp['lat']),\n",
    "            lon = np.array(darray_temp['lon'])\n",
    "        ),\n",
    "        attrs = dict(\n",
    "            description = \"Mean Absolute Error\"\n",
    "        )\n",
    "    )\n",
    "    darray_mae.name = \"mae\"\n",
    "    darray_mae.attrs[\"units\"] = \"ppm per (micromol m-2 s-1)\"\n",
    "    darray_mae.attrs[\"long_name\"] = \"Mean Absolute Error\"\n",
    "\n",
    "    darray_mae.lon.attrs['units'] = \"degrees_east\"\n",
    "    darray_mae.lon.attrs['long_name'] = \"longitude in degree east\"\n",
    "    darray_mae.lon.attrs['description'] = \"grid cell centers\"\n",
    "\n",
    "    darray_mae.lat.attrs['units'] = \"degrees_north\"\n",
    "    darray_mae.lat.attrs['long_name'] = \"longitude in degree north\"\n",
    "    darray_mae.lat.attrs['description'] = \"grid cell centers\"\n",
    "    return darray_mae\n",
    "\n",
    "def get_darray_bias(array_bias,darray_temp):\n",
    "    \"\"\"convert array bias to xarray dataarray\n",
    "        darray_bias: target array\n",
    "        darray_temp: provide darray shape, i.e. lon and lat for the array\n",
    "    \"\"\"\n",
    "    darray_bias = xr.DataArray(\n",
    "        array_bias,\n",
    "        dims=[\"lat\",\"lon\"],\n",
    "        coords=dict(\n",
    "            lat = np.array(darray_temp['lat']),\n",
    "            lon = np.array(darray_temp['lon'])\n",
    "        ),\n",
    "        attrs = dict(\n",
    "            description = \"Mean Error\"\n",
    "        )\n",
    "    )\n",
    "    darray_bias.name = \"bias\"\n",
    "    darray_bias.attrs[\"units\"] = \"ppm per (micromol m-2 s-1)\"\n",
    "    darray_bias.attrs[\"long_name\"] = \"Mean Error\"\n",
    "\n",
    "    darray_bias.lon.attrs['units'] = \"degrees_east\"\n",
    "    darray_bias.lon.attrs['long_name'] = \"longitude in degree east\"\n",
    "    darray_bias.lon.attrs['description'] = \"grid cell centers\"\n",
    "\n",
    "    darray_bias.lat.attrs['units'] = \"degrees_north\"\n",
    "    darray_bias.lat.attrs['long_name'] = \"longitude in degree north\"\n",
    "    darray_bias.lat.attrs['description'] = \"grid cell centers\"\n",
    "    return darray_bias\n",
    "\n",
    "def get_darray_IoA(array_IoA,darray_temp):\n",
    "    \"\"\"convert array IoA to xarray dataarray\n",
    "        darray_IoA: target array\n",
    "        darray_temp: provide darray shape, i.e. lon and lat for the array\n",
    "    \"\"\"\n",
    "    darray_IoA = xr.DataArray(\n",
    "        array_IoA,\n",
    "        dims=[\"lat\",\"lon\"],\n",
    "        coords=dict(\n",
    "            lat = np.array(darray_temp['lat']),\n",
    "            lon = np.array(darray_temp['lon'])\n",
    "        ),\n",
    "        attrs = dict(\n",
    "            description = \"Index of agreement\"\n",
    "        )\n",
    "    )\n",
    "    darray_IoA.name = \"IoA\"\n",
    "    darray_IoA.attrs[\"units\"] = \"1\"\n",
    "    darray_IoA.attrs[\"long_name\"] = \"Index of agreement\"\n",
    "\n",
    "    darray_IoA.lon.attrs['units'] = \"degrees_east\"\n",
    "    darray_IoA.lon.attrs['long_name'] = \"longitude in degree east\"\n",
    "    darray_IoA.lon.attrs['description'] = \"grid cell centers\"\n",
    "\n",
    "    darray_IoA.lat.attrs['units'] = \"degrees_north\"\n",
    "    darray_IoA.lat.attrs['long_name'] = \"longitude in degree north\"\n",
    "    darray_IoA.lat.attrs['description'] = \"grid cell centers\"\n",
    "    return darray_IoA\n",
    "\n",
    "def get_darray_rpd(array_rpd,darray_temp):\n",
    "    \"\"\"convert array rpd to xarray dataarray\n",
    "        darray_rpd: target array\n",
    "        darray_temp: provide darray shape, i.e. lon and lat for the array\n",
    "    \"\"\"\n",
    "    darray_rpd = xr.DataArray(\n",
    "        array_rpd,\n",
    "        dims=[\"lat\",\"lon\"],\n",
    "        coords=dict(\n",
    "            lat = np.array(darray_temp['lat']),\n",
    "            lon = np.array(darray_temp['lon'])\n",
    "        ),\n",
    "        attrs = dict(\n",
    "            description = \"Relative percentage difference\"\n",
    "        )\n",
    "    )\n",
    "    darray_rpd.name = \"rpd\"\n",
    "    darray_rpd.attrs[\"units\"] = \"%\"\n",
    "    darray_rpd.attrs[\"long_name\"] = \"Relative percentage difference\"\n",
    "\n",
    "    darray_rpd.lon.attrs['units'] = \"degrees_east\"\n",
    "    darray_rpd.lon.attrs['long_name'] = \"longitude in degree east\"\n",
    "    darray_rpd.lon.attrs['description'] = \"grid cell centers\"\n",
    "    darray_rpd.lon.attrs['axis'] = \"X\"\n",
    "\n",
    "    darray_rpd.lat.attrs['units'] = \"degrees_north\"\n",
    "    darray_rpd.lat.attrs['long_name'] = \"longitude in degree north\"\n",
    "    darray_rpd.lat.attrs['description'] = \"grid cell centers\"\n",
    "    darray_rpd.lat.attrs['axis'] = \"Y\"\n",
    "    return darray_rpd\n",
    "\n",
    "def get_darray_rdmf(array_rdmf,darray_temp):\n",
    "    \"\"\"convert array rdmf to xarray dataarray\n",
    "        darray_rdmf: target array\n",
    "        darray_temp: provide darray shape, i.e. lon and lat for the array\n",
    "    \"\"\"\n",
    "    darray_rdmf = xr.DataArray(\n",
    "        array_rdmf,\n",
    "        dims=[\"lat\",\"lon\"],\n",
    "        coords=dict(\n",
    "            lat = np.array(darray_temp['lat']),\n",
    "            lon = np.array(darray_temp['lon'])\n",
    "        ),\n",
    "        attrs = dict(\n",
    "            description = \"Relative difference of the mean footprint\"\n",
    "        )\n",
    "    )\n",
    "    darray_rdmf.name = \"rdmf\"\n",
    "    darray_rdmf.attrs[\"units\"] = \"%\"\n",
    "    darray_rdmf.attrs[\"long_name\"] = \"Relative difference of the mean footprint\"\n",
    "\n",
    "    darray_rdmf.lon.attrs['units'] = \"degrees_east\"\n",
    "    darray_rdmf.lon.attrs['long_name'] = \"longitude in degree east\"\n",
    "    darray_rdmf.lon.attrs['description'] = \"grid cell centers\"\n",
    "    darray_rdmf.lon.attrs['axis'] = \"X\"\n",
    "\n",
    "    darray_rdmf.lat.attrs['units'] = \"degrees_north\"\n",
    "    darray_rdmf.lat.attrs['long_name'] = \"longitude in degree north\"\n",
    "    darray_rdmf.lat.attrs['description'] = \"grid cell centers\"\n",
    "    darray_rdmf.lat.attrs['axis'] = \"Y\"\n",
    "    return darray_rdmf\n",
    "\n",
    "def get_6stat(darray_afternoon_stilt,darray_afternoon_flexpart):\n",
    "    \"\"\" compute 6 statistics, r, rmse, mae, bias, IoA, rpd\n",
    "        darray_afternoon_stilt: data array with the same shape\n",
    "        darray_afternoon_flexpart: data array with the same shape\n",
    "    \"\"\"\n",
    "    nlon = len(darray_afternoon_stilt['lon'])\n",
    "    nlat = len(darray_afternoon_stilt['lat'])\n",
    "    array_r = np.empty((nlat,nlon))\n",
    "    array_r[:] = np.NaN\n",
    "    array_rmse = np.empty((nlat,nlon))\n",
    "    array_rmse[:] = np.NaN\n",
    "    array_mae = np.empty((nlat,nlon))\n",
    "    array_mae[:] = np.NaN\n",
    "    array_bias = np.empty((nlat,nlon))\n",
    "    array_bias[:] = np.NaN\n",
    "    array_IoA = np.empty((nlat,nlon))\n",
    "    array_IoA[:] = np.NaN\n",
    "    array_rpd = np.empty((nlat,nlon))\n",
    "    array_rpd[:] = np.NaN\n",
    "    for lon in range(nlon):\n",
    "        for lat in range(nlat):\n",
    "            array_r[lat,lon] = correlation(darray_afternoon_stilt.values[:,lat,lon],darray_afternoon_flexpart.values[:,lat,lon])\n",
    "            array_rmse[lat,lon] = rmse(darray_afternoon_stilt.values[:,lat,lon],darray_afternoon_flexpart.values[:,lat,lon])\n",
    "            array_mae[lat,lon] = mae(darray_afternoon_stilt.values[:,lat,lon],darray_afternoon_flexpart.values[:,lat,lon])\n",
    "            array_bias[lat,lon] = bias(darray_afternoon_stilt.values[:,lat,lon],darray_afternoon_flexpart.values[:,lat,lon])\n",
    "            array_IoA[lat,lon] = index_agreement(darray_afternoon_stilt.values[:,lat,lon],darray_afternoon_flexpart.values[:,lat,lon])\n",
    "            array_rpd[lat,lon] = rpd(darray_afternoon_stilt.values[:,lat,lon],darray_afternoon_flexpart.values[:,lat,lon])\n",
    "        if lon % 20 ==0:\n",
    "            print(lon,end=\"..\")\n",
    "    print(\"done\")\n",
    "    return array_r, array_rmse, array_mae, array_bias, array_IoA, array_rpd\n",
    "\n",
    "def plot_conf_matrix(df_flexpart, df_stilt, yearmon, lt, threshold, ax):\n",
    "    y_flexpart = df_flexpart>threshold\n",
    "    y_stilt = df_stilt>threshold\n",
    "    conf_matrix = metrics.confusion_matrix(y_stilt, y_flexpart)\n",
    "    accuracy = round(np.sum(conf_matrix.diagonal())/np.sum(conf_matrix)*100,1)\n",
    "\n",
    "    alpha = [f'<={threshold}',f'>{threshold}']\n",
    "    ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.6)\n",
    "    for i in range(conf_matrix.shape[0]):\n",
    "        for j in range(conf_matrix.shape[1]):\n",
    "            ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    "    xaxis = np.arange(len(alpha))\n",
    "    ax.set_xticks(xaxis)\n",
    "    ax.set_yticks(xaxis)\n",
    "    ax.set_xticklabels(alpha)\n",
    "    ax.set_yticklabels(alpha);\n",
    "    ax.set_xlabel('Flexpart ∆14C', fontsize=12)\n",
    "    ax.set_ylabel('Stilt ∆14C', fontsize=12)\n",
    "    ax.set_title(f'{yearmon} {lt}LT, agreement={accuracy}%', fontsize=12, loc = \"left\")\n",
    "\n",
    "def plot_hist(df_flexpart, df_stilt, yearmon,  ax):\n",
    "    data1 = df_flexpart['mean']\n",
    "    data2 = df_stilt['mean']\n",
    "\n",
    "    nbin = [i*0.2 for i in range(50)]\n",
    "    ax.hist(data1, bins=nbin, alpha=0.7, label='Flexpart afternoon ∆14C')\n",
    "    ax.hist(data2, bins=nbin, alpha=0.7, label='Stilt afternoon ∆14C')\n",
    "\n",
    "    ax.grid()\n",
    "    ax.set_xlim(0,10)\n",
    "    ax.set_xticks(range(11))\n",
    "    ax.set_xticklabels(range(11))\n",
    "    ax.set_xlabel('∆14C, [‰]')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_title(f'Histogram Comparison, {yearmon}',loc = \"left\")\n",
    "    ax.tick_params(axis='x', labelrotation = 0)\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "274a9fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_footprint(path, StationID, sdate, edate, fname=\"foot_nest\", domain=\"eu\"):\n",
    "    \"\"\"\n",
    "    Merge hourly footprint files for a station over a period and save as NetCDF.\n",
    "\n",
    "    Parameters:\n",
    "        path (str): Base directory for FLEXPART output.\n",
    "        StationID (str): Station identifier.\n",
    "        sdate (str): Start date, format 'YYYY-MM-DD'.\n",
    "        edate (str): End date, format 'YYYY-MM-DD'.\n",
    "        fname (str): File name to read ('foot' or 'foot_nest').\n",
    "        domain (str): Domain identifier for output file naming.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    StationID = StationID.upper()\n",
    "    period = pd.date_range(start=sdate, end=edate)\n",
    "    darray_flexpart = None\n",
    "    i = 0\n",
    "    print(f\"{StationID}: \", flush=True)\n",
    "    for date in period:\n",
    "        Year = str(date.year)\n",
    "        Month = str(date.month).zfill(2)\n",
    "        Day = str(date.day).zfill(2)\n",
    "        for Hour in range(24):\n",
    "            folder = f\"{Year}x{Month}x{Day}x{str(Hour).zfill(2)}\"\n",
    "            file_path = f\"{path}{StationID}/{Year}/{Month}/{folder}/{fname}\"\n",
    "            try:\n",
    "                darray_temp = xr.open_dataarray(file_path)\n",
    "                darray_temp = darray_temp.where(darray_temp != 0)\n",
    "                if darray_flexpart is None:\n",
    "                    darray_flexpart = darray_temp\n",
    "                else:\n",
    "                    darray_flexpart = xr.concat([darray_flexpart, darray_temp], dim=\"time\")\n",
    "            except Exception as e:\n",
    "                print(f\"Missing or error in file: {file_path} -- {e}\")\n",
    "        i += 1\n",
    "        if i % 10 == 0:\n",
    "            print(f\"{date}...\", end=\"\", flush=True)\n",
    "    if darray_flexpart is not None:\n",
    "        file_path_name = f\"{path}{StationID}/foot_{domain}_{sdate}_{edate}_flexpart.nc\"\n",
    "        if exists(file_path_name):\n",
    "            remove(file_path_name)\n",
    "        darray_flexpart.to_netcdf(file_path_name)\n",
    "        print(f\"\\nSaved {file_path_name}\")\n",
    "    else:\n",
    "        print(f\"\\nNo data found for {StationID} in period {sdate} to {edate}\")\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"{StationID} took {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d4551e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_footprint_out(IN_PATH, OUT_PATH, StationID, sdate, edate, fname=\"foot_nest\", domain=\"eu\"):\n",
    "    \"\"\"\n",
    "    Merge hourly footprint files for a station over a period and save as NetCDF to OUT_PATH.\n",
    "\n",
    "    Parameters:\n",
    "        IN_PATH (str): Base directory for FLEXPART input files.\n",
    "        OUT_PATH (str): Output directory for merged NetCDF.\n",
    "        StationID (str): Station identifier.\n",
    "        sdate (str): Start date, format 'YYYY-MM-DD'.\n",
    "        edate (str): End date, format 'YYYY-MM-DD'.\n",
    "        fname (str): File name to read ('foot' or 'foot_nest').\n",
    "        domain (str): Domain identifier for output file naming.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    StationID = StationID.upper()\n",
    "    period = pd.date_range(start=sdate, end=edate)\n",
    "    darray_flexpart = None\n",
    "    i = 0\n",
    "    print(f\"{StationID}: \", flush=True)\n",
    "    for date in period:\n",
    "        Year = str(date.year)\n",
    "        Month = str(date.month).zfill(2)\n",
    "        Day = str(date.day).zfill(2)\n",
    "        for Hour in range(24):\n",
    "            folder = f\"{Year}x{Month}x{Day}x{str(Hour).zfill(2)}\"\n",
    "            file_path = f\"{IN_PATH}{StationID}/{Year}/{Month}/{folder}/{fname}\"\n",
    "            try:\n",
    "                darray_temp = xr.open_dataarray(file_path)\n",
    "                darray_temp = darray_temp.where(darray_temp != 0)\n",
    "                if darray_flexpart is None:\n",
    "                    darray_flexpart = darray_temp\n",
    "                else:\n",
    "                    darray_flexpart = xr.concat([darray_flexpart, darray_temp], dim=\"time\")\n",
    "            except Exception as e:\n",
    "                print(f\"Missing or error in file: {file_path} -- {e}\")\n",
    "        i += 1\n",
    "        if i % 5 == 0:\n",
    "            print(f\"{date}...\", end=\"\", flush=True)\n",
    "    if darray_flexpart is not None:\n",
    "        out_dir = join(OUT_PATH, StationID)\n",
    "        if not exists(out_dir):\n",
    "            makedirs(out_dir)\n",
    "        file_path_name = join(out_dir, f\"foot_{domain}_{sdate}_{edate}_flexpart.nc\")\n",
    "        if exists(file_path_name):\n",
    "            remove(file_path_name)\n",
    "        darray_flexpart.to_netcdf(file_path_name)\n",
    "        print(f\"\\nSaved {file_path_name}\")\n",
    "    else:\n",
    "        print(f\"\\nNo data found for {StationID} in period {sdate} to {edate}\")\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"{StationID} took {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc82cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_hour_file(file_path):\n",
    "    try:\n",
    "        darray_temp = xr.open_dataarray(file_path)\n",
    "        return darray_temp.where(darray_temp != 0)\n",
    "    except Exception as e:\n",
    "        print(f\"Missing or error in file: {file_path} -- {e}\")\n",
    "        return None\n",
    "\n",
    "def merge_footprint_parallel(IN_PATH, OUT_PATH, StationID, sdate, edate, fname=\"foot_nest\", domain=\"eu\", ncpu=5):\n",
    "    start_time = time.time()\n",
    "    StationID = StationID.upper()\n",
    "    period = pd.date_range(start=sdate, end=edate)\n",
    "    file_paths = []\n",
    "    print(f\"{StationID}: {fname} for {domain} domain\", flush=True)\n",
    "    for date in period:\n",
    "        Year = str(date.year)\n",
    "        Month = str(date.month).zfill(2)\n",
    "        Day = str(date.day).zfill(2)\n",
    "        for Hour in range(24):\n",
    "            folder = f\"{Year}x{Month}x{Day}x{str(Hour).zfill(2)}\"\n",
    "            file_path = f\"{IN_PATH}{StationID}/{Year}/{Month}/{folder}/{fname}\"\n",
    "            file_paths.append(file_path)\n",
    "    # Parallel read\n",
    "    results = Parallel(n_jobs=ncpu, verbose=5)(delayed(read_hour_file)(fp) for fp in file_paths)\n",
    "    # Filter out None\n",
    "    darrays = [r for r in results if r is not None]\n",
    "    if darrays:\n",
    "        darray_flexpart = xr.concat(darrays, dim=\"time\")\n",
    "        out_dir = join(OUT_PATH, StationID)\n",
    "        if not exists(out_dir):\n",
    "            makedirs(out_dir)\n",
    "        file_path_name = join(out_dir, f\"foot_{domain}_{sdate}_{edate}_flexpart.nc\")\n",
    "        if exists(file_path_name):\n",
    "            remove(file_path_name)\n",
    "        darray_flexpart.to_netcdf(file_path_name)\n",
    "        print(f\"\\nSaved {file_path_name}\")\n",
    "    else:\n",
    "        print(f\"\\nNo data found for {StationID} in period {sdate} to {edate}\")\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"{StationID} took {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41a896b",
   "metadata": {},
   "source": [
    "# 2. Merge hourly footprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae622c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths and parameters\n",
    "lst_Station = [\"htm150\", \"ope120\", \"gat341\", \"lin098\", \"cbw200\"]\n",
    "FLEXPARTv10_PATH = \"/data/cupcake/flexpartweb/stations/\"\n",
    "FLEXPARTv11_PATH = \"/data/cupcake/flexpartweb/stations/\"\n",
    "FLEXPARTv10_EU_PATH = \"/data/cupcake/flexpartweb/stations_eu/\"\n",
    "FLEXPARTv11_EU_PATH = \"/data/cupcake/flexpartweb/stations_eu/\"\n",
    "OUTv10_PATH = \"/data/flexpart/output/v10/flexpartweb/stations/\"\n",
    "OUTv11_PATH = \"/data/flexpart/output/v11/flexpartweb/stations/\"\n",
    "OUTv10_EU_PATH = \"/data/flexpart/output/v10/flexpartweb/stations_eu/\"\n",
    "OUTv11_EU_PATH = \"/data/flexpart/output/v11/flexpartweb/stations_eu/\"\n",
    "sdate = '2025-08-01'\n",
    "edate = '2025-08-20'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd9e3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge footprint files for each station and domain\n",
    "for StationID in lst_Station:\n",
    "    # merge_footprint(FLEXPARTv10_PATH, StationID, sdate, edate, fname=\"foot\", domain=\"global\")\n",
    "    # merge_footprint(FLEXPARTv11_PATH, StationID, sdate, edate, fname=\"foot\", domain=\"global\")\n",
    "    # merge_footprint(FLEXPARTv10_PATH, StationID, sdate, edate, fname=\"foot_nest\", domain=\"global_nest\")\n",
    "    # merge_footprint(FLEXPARTv11_PATH, StationID, sdate, edate, fname=\"foot_nest\", domain=\"global_nest\")\n",
    "    # merge_footprint(FLEXPARTv10_EU_PATH, StationID, sdate, edate, fname=\"foot\", domain=\"eu\")\n",
    "    # merge_footprint(FLEXPARTv11_EU_PATH, StationID, sdate, edate, fname=\"foot\", domain=\"eu\")\n",
    "    # merge_footprint_out(FLEXPARTv10_PATH, OUTv10_PATH, StationID, sdate, edate, fname=\"foot\", domain=\"global\")\n",
    "    # merge_footprint_out(FLEXPARTv11_PATH, OUTv11_PATH, StationID, sdate, edate, fname=\"foot\", domain=\"global\")\n",
    "    # merge_footprint_out(FLEXPARTv10_PATH, OUTv10_PATH, StationID, sdate, edate, fname=\"foot_nest\", domain=\"global_nest\")\n",
    "    # merge_footprint_out(FLEXPARTv11_PATH, OUTv11_PATH, StationID, sdate, edate, fname=\"foot_nest\", domain=\"global_nest\")\n",
    "    # merge_footprint_out(FLEXPARTv10_EU_PATH, OUTv10_EU_PATH, StationID, sdate, edate, fname=\"foot\", domain=\"eu\")\n",
    "    # merge_footprint_out(FLEXPARTv11_EU_PATH, OUTv11_EU_PATH, StationID, sdate, edate, fname=\"foot\", domain=\"eu\")\n",
    "    merge_footprint_parallel(FLEXPARTv10_PATH, OUTv10_PATH, StationID, sdate, edate, fname=\"foot\", domain=\"global\")\n",
    "    merge_footprint_parallel(FLEXPARTv11_PATH, OUTv11_PATH, StationID, sdate, edate, fname=\"foot\", domain=\"global\")\n",
    "    merge_footprint_parallel(FLEXPARTv10_PATH, OUTv10_PATH, StationID, sdate, edate, fname=\"foot_nest\", domain=\"global_nest\")\n",
    "    merge_footprint_parallel(FLEXPARTv11_PATH, OUTv11_PATH, StationID, sdate, edate, fname=\"foot_nest\", domain=\"global_nest\")\n",
    "    merge_footprint_parallel(FLEXPARTv10_EU_PATH, OUTv10_EU_PATH, StationID, sdate, edate, fname=\"foot\", domain=\"eu\")\n",
    "    merge_footprint_parallel(FLEXPARTv11_EU_PATH, OUTv11_EU_PATH, StationID, sdate, edate, fname=\"foot\", domain=\"eu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d202075-9bc8-4cda-a43b-4c2582d5285c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTM150: \n",
      "\n",
      "Saved /data/flexpart/output/v10/flexpartweb/stations/HTM150/foot_global_2025-08-01_2025-08-02_flexpart.nc\n",
      "HTM150 took 1.68 seconds\n"
     ]
    }
   ],
   "source": [
    "sdate = '2025-08-01'\n",
    "edate = '2025-08-02'\n",
    "StationID = \"htm150\"\n",
    "merge_footprint_out(FLEXPARTv10_PATH, OUTv10_PATH, StationID, sdate, edate, fname=\"foot\", domain=\"global\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a8514e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTM150: \n",
      "2025-08-05 00:00:00...2025-08-10 00:00:00...\n",
      "Saved /data/flexpart/output/v10/flexpartweb/stations/HTM150/foot_global_2025-08-01_2025-08-10_flexpart.nc\n",
      "HTM150 took 211.04 seconds\n"
     ]
    }
   ],
   "source": [
    "sdate = '2025-08-01'\n",
    "edate = '2025-08-10'\n",
    "StationID = \"htm150\"\n",
    "merge_footprint_out(FLEXPARTv10_PATH, OUTv10_PATH, StationID, sdate, edate, fname=\"foot\", domain=\"global\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5b3c2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12adc888",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_Station = [\"htm150\", \"ope120\", \"gat341\", \"lin098\", \"cbw200\"]\n",
    "FLEXPART_PATH = FLEXPARTv10_PATH  # or FLEXPARTv11_PATH, set as needed\n",
    "sdate = '2025-08-01'\n",
    "edate = '2025-08-20'\n",
    "period = pd.date_range(start=sdate, end=edate, inclusive='both')\n",
    "\n",
    "for StationID in lst_Station:\n",
    "    i = 0\n",
    "    darray_flexpart = None\n",
    "    for date in period:\n",
    "        Year = str(date.year)\n",
    "        Month = str(date.month).zfill(2)\n",
    "        Day = str(date.day).zfill(2)\n",
    "        for Hour in range(24):\n",
    "            floder_Flexpart = Year + \"x\" + Month + \"x\" + Day + \"x\" + str(Hour).zfill(2)\n",
    "            file_path = FLEXPART_PATH + StationID + \"/\" + Year + \"/\" + Month + \"/\" + floder_Flexpart + \"/foot_nest\"\n",
    "            try:\n",
    "                darray_temp = xr.open_dataarray(file_path)\n",
    "                darray_temp = darray_temp.where(darray_temp != 0)\n",
    "                if darray_flexpart is None:\n",
    "                    darray_flexpart = darray_temp\n",
    "                else:\n",
    "                    darray_flexpart = xr.concat([darray_flexpart, darray_temp], dim=\"time\")\n",
    "            except Exception as e:\n",
    "                print(f\"Missing or error in file: {file_path} -- {e}\")\n",
    "        i += 1\n",
    "        if i % 10 == 0:\n",
    "            print(f\"{StationID}: {date}...\", end=\"\")\n",
    "    if darray_flexpart is not None:\n",
    "        file_path_name = FLEXPART_PATH + StationID + \"/\" + f\"foot_eu_{sdate}_{edate}_flexpart.nc\"\n",
    "        # Remove file if exists\n",
    "        if exists(file_path_name):\n",
    "            remove(file_path_name)\n",
    "        darray_flexpart.to_netcdf(file_path_name)\n",
    "        print(f\"\\nSaved {file_path_name}\")\n",
    "    else:\n",
    "        print(f\"\\nNo data found for {StationID} in period {sdate} to {edate}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5cbe8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
